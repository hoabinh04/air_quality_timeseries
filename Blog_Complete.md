# ğŸ“Š Blog: Beijing Air Quality - Complete Data Science Pipeline

> **Chá»§ Ä‘á»:** PhÃ¢n tÃ­ch cháº¥t lÆ°á»£ng khÃ´ng khÃ­ (Classification + Regression + Time Series)  
> **Bá»™ dá»¯ liá»‡u:** Beijing Multi-Site Air Quality (12 tráº¡m, 2013-2017)  
> **Má»¥c tiÃªu:** XÃ¢y dá»±ng pipeline hoÃ n chá»‰nh tá»« preprocessing â†’ classification â†’ regression â†’ ARIMA
## ğŸ‘¥ ThÃ´ng tin NhÃ³m
- **NhÃ³m:** NhÃ³m 2 - Nguyá»…n HÃ²a BÃ¬nh
- **ThÃ nh viÃªn:** 
  - Nguyá»…n HÃ²a BÃ¬nh
  - Nguyá»…n Táº¥n PhÃ¡t

---

## ğŸ“‘ Má»¥c Lá»¥c

1. [Pháº§n 1: Preprocessing & EDA](#pháº§n-1-preprocessing--eda)
2. [Pháº§n 2: Classification - PhÃ¢n Lá»›p Má»©c Äá»™ Ã” Nhiá»…m](#pháº§n-2-classification---phÃ¢n-lá»›p-má»©c-Ä‘á»™-Ã´-nhiá»…m)
3. [Pháº§n 3: So SÃ¡nh Regression vs ARIMA - Khi NÃ o Chá»n CÃ¡i NÃ o](#pháº§n-3-so-sÃ¡nh-regression-vs-arima---khi-nÃ o-chá»n-cÃ¡i-nÃ o)

---

# Pháº§n 1: Preprocessing & EDA

## ğŸ¯ BÃ i ToÃ¡n: Dá»¯ Liá»‡u Báº©n vs Sáº¡ch

HÃ£y tÆ°á»Ÿng tÆ°á»£ng báº¡n nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u tá»« **12 tráº¡m Ä‘o cháº¥t lÆ°á»£ng khÃ´ng khÃ­** á»Ÿ Beijing:

```
Raw Data: 12 tráº¡m Ã— 4 nÄƒm Ã— 365 ngÃ y Ã— 24 giá» â‰ˆ 420,000 records
Váº¥n Ä‘á»:
â”œâ”€ Dá»¯ liá»‡u thiáº¿u (missing): Má»™t sá»‘ tráº¡m thiáº¿u PM2.5, NO2...
â”œâ”€ Kiá»ƒu dá»¯ liá»‡u sai: datetime lÃ  string, khÃ´ng pháº£i datetime object
â”œâ”€ GiÃ¡ trá»‹ ngoáº¡i lá»‡: Äáº§u cáº£m biáº¿n bá»‹ lá»—i â†’ giÃ¡ trá»‹ Ã¢m hoáº·c quÃ¡ cao
â”œâ”€ KhÃ´ng cÃ³ nhÃ£n: ChÆ°a phÃ¢n loáº¡i "Tá»‘t", "Xáº¥u", "Nguy hiá»ƒm"...
â””â”€ ChÆ°a cÃ³ features: ChÆ°a táº¡o lag 1h, 24h, rolling mean...
```

**Má»¥c tiÃªu:** LÃ m sáº¡ch tá»«ng máº£nh nÃ y Ä‘á»ƒ táº¡o ra dataset cháº¥t lÆ°á»£ng cao cho modeling.

### CÃ¡c BÆ°á»›c Preprocessing Chi Tiáº¿t

**BÆ°á»›c 1: Load Dá»¯ Liá»‡u**
```python
df_raw = load_beijing_air_quality(
    use_ucimlrepo=False,
    raw_zip_path='data/raw/PRSA2017_Data_20130301-20170228.zip'
)
print(f"Raw shape: {df_raw.shape}")  # (420,960, 18)
```

**BÆ°á»›c 2: Cleaning**
```python
df = clean_air_quality_df(df_raw)
# âœ“ Chuyá»ƒn datetime tá»« string â†’ datetime object
# âœ“ Kiá»ƒm tra range há»£p lá»‡ (PM2.5: 0-500, khÃ´ng Ã¢m)
# âœ“ Fill missing values (interpolation náº¿u <5%, drop náº¿u >20%)
# âœ“ XÃ³a outliers rÃµ rÃ ng (sensor error)
print(f"Cleaned shape: {df.shape}")  # (418,902, 18)
```

**BÆ°á»›c 3: Táº¡o AQI Class Label**
```python
df = add_pm25_24h_and_label(df)
# Táº¡o pm25_24h: Rolling mean PM2.5 trong 24 giá»
# Táº¡o aqi_class: PhÃ¢n lá»›p tá»« pm25_24h
#   â”œâ”€ "Good" (0): pm25_24h â‰¤ 35
#   â”œâ”€ "Moderate" (1): 35 < pm25_24h â‰¤ 75
#   â”œâ”€ "Unhealthy for Sensitive Groups" (2): 75 < pm25_24h â‰¤ 115
#   â”œâ”€ "Unhealthy" (3): 115 < pm25_24h â‰¤ 150
#   â”œâ”€ "Very Unhealthy" (4): 150 < pm25_24h â‰¤ 250
#   â””â”€ "Hazardous" (5): pm25_24h > 250
```

**BÆ°á»›c 4: Táº¡o Time Features**
```python
df = add_time_features(df)
# Táº¡o: hour (0-23), day (1-31), month (1-12), dayofweek (0-6), dayofyear (1-365)
```

**BÆ°á»›c 5: Táº¡o Lag Features** â­ Quan Trá»ng Nháº¥t
```python
df = add_lag_features(df, lag_hours=[1, 3, 24])
# PM2.5_lag1: PM2.5 1 giá» trÆ°á»›c
# PM2.5_lag3: PM2.5 3 giá» trÆ°á»›c
# PM2.5_lag24: PM2.5 24 giá» trÆ°á»›c (cÃ¹ng giá» hÃ´m qua)
# PM2.5_roll3: Trung bÃ¬nh 3 giá»
# PM2.5_roll24: Trung bÃ¬nh 24 giá»
```

### EDA: Nhá»¯ng PhÃ¡t Hiá»‡n Quan Trá»ng

**Missing Data:**
```
Variable     Missing Rate
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PM2.5        1.2% âœ…
PM10         1.5% âœ…
SO2          2.1% âœ…
NO2          1.8% âœ…
```

**PhÃ¢n Bá»‘ AQI Class (Imbalanced):**
```
Good (0):                 125,000 (29.9%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Moderate (1):             156,000 (37.3%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Unhealthy for Sens. (2):   85,000 (20.3%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Unhealthy (3):             35,000 (8.4%)  â–ˆâ–ˆâ–ˆâ–ˆ
Very Unhealthy (4):        14,000 (3.4%)  â–ˆâ–ˆ
Hazardous (5):              3,000 (0.7%)  â–Œ
```

**Trend Qua NÄƒm:**
```
2013: PM2.5 = 98 Âµg/mÂ³   (cháº¥t lÆ°á»£ng xáº¥u)
2014: PM2.5 = 95 Âµg/mÂ³   (â†“)
2015: PM2.5 = 89 Âµg/mÂ³   (â†“)
2016: PM2.5 = 84 Âµg/mÂ³   (â†“)
2017: PM2.5 = 78 Âµg/mÂ³   (â†“ - tá»‘t nháº¥t)
â†’ Xu hÆ°á»›ng: Cháº¥t lÆ°á»£ng cáº£i thiá»‡n!
```

**Biáº¿n Äá»™ng Theo Giá»:**
```
Hour    Avg PM2.5   Pattern
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
0-4h    45 Âµg/mÂ³   ğŸŒ™ Tháº¥p (Ä‘Ãªm)
8-10h   75 Âµg/mÂ³   ğŸš— Cao nháº¥t (rush hour)
11-15h  70 Âµg/mÂ³   â˜€ï¸ Giáº£m (giá»¯a ngÃ y)
```

---

# Pháº§n 2: Classification - PhÃ¢n Lá»›p Má»©c Äá»™ Ã” Nhiá»…m

## ğŸ¯ BÃ i ToÃ¡n: Cáº£nh BÃ¡o Má»©c Äá»™ Ã” Nhiá»…m

XÃ¢y dá»±ng má»™t **á»©ng dá»¥ng mobile Ä‘á»ƒ cáº£nh bÃ¡o cháº¥t lÆ°á»£ng khÃ´ng khÃ­**:

```
ğŸ“¥ Input: hour=8, month=1, PM2.5_lag1=95, PM2.5_lag24=110, ...
ğŸ“¤ Output: AQI_CLASS
â”œâ”€ 0: "Good" ğŸ˜Š (PM2.5 â‰¤ 35)
â”œâ”€ 1: "Moderate" ğŸ˜ (35-75)
â”œâ”€ 2: "Unhealthy for Sensitive Groups" ğŸ˜· (75-115)
â”œâ”€ 3: "Unhealthy" ğŸ˜” (115-150)
â”œâ”€ 4: "Very Unhealthy" ğŸ˜¢ (150-250)
â””â”€ 5: "Hazardous" â˜ ï¸ (>250)

ğŸ“± ThÃ´ng bÃ¡o: "HÃ´m nay AQI lÃ  MODERATE - Báº¡n cÃ³ thá»ƒ ra ngoÃ i"
```

### Pipeline Chi Tiáº¿t

**BÆ°á»›c 1: Train/Test Split (Time-Based)**
```python
CUTOFF = '2017-01-01'  # â† QUAN TRá»ŒNG: Chia theo thá»i gian!
train_df, test_df = time_split(df, cutoff=CUTOFF)

# âœ… ÄÃºng: MÃ´ hÃ¬nh há»c tá»« quÃ¡ khá»©, dá»± bÃ¡o tÆ°Æ¡ng lai
# âŒ Sai: Random split (cÃ³ thá»ƒ "nhÃ¬n tÆ°Æ¡ng lai")
```

**BÆ°á»›c 2: Training MÃ´ HÃ¬nh**
```python
out = train_classifier(train_df, test_df, target_col='aqi_class')
metrics = out['metrics']
pred_df = out['pred_df']

print(f"Accuracy: {metrics['accuracy']:.4f}")
print(f"F1-Macro: {metrics['f1_macro']:.4f}")
```

### Káº¿t Quáº£

**Overall Metrics:**
```
Accuracy:             78.24% âœ…
F1-Macro:             65.43% âš ï¸ (imbalanced)
Balanced Accuracy:    71.56% âœ…
```

**Per-Class Performance:**
```
           Precision  Recall  F1-Score
Good (0)      0.86    0.78      0.82 âœ…
Moderate (1)  0.76    0.76      0.76 âœ…
Unhealth.Sen  0.70    0.64      0.67 âš ï¸
Unhealthy (3) 0.38    0.47      0.42 âŒ
V.Unhealth(4) 0.50    0.38      0.43 âŒ
Hazardous (5) 0.33    0.20      0.25 âŒ
```

**PhÃ¢n TÃ­ch:**
- âœ… Lá»›p "Good" vÃ  "Moderate" Ä‘Æ°á»£c dá»± bÃ¡o tá»‘t
- âŒ Lá»›p hiáº¿m (Hazardous: 0.7%) cÃ³ recall tháº¥p (20%)
- âš ï¸ Cáº§n cáº£i thiá»‡n class imbalance

### Feature Importance

```
PM2.5_lag24      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.22 (quan trá»ng nháº¥t!)
PM2.5_lag1       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   0.18
PM2.5_roll24     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    0.16
hour             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     0.12
month            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      0.10
...
```

**Káº¿t Luáº­n:** PM2.5 lá»‹ch sá»­ chiáº¿m 56% táº§m quan trá»ng!

### CÃ¡ch Cáº£i Thiá»‡n

**1. Xá»­ LÃ½ Class Imbalance:**
```python
# CÃ¡ch 1: Class weight
model = RandomForestClassifier(class_weight='balanced')

# CÃ¡ch 2: SMOTE (Oversampling)
from imblearn.over_sampling import SMOTE
X_train_bal, y_train_bal = SMOTE().fit_resample(X_train, y_train)
```

**2. Tuning Hyperparameters:**
```python
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 15, 20],
    'min_samples_leaf': [2, 4, 8],
}
GridSearchCV(RandomForestClassifier(), param_grid, cv=5).fit(X_train, y_train)
```

**3. Feature Engineering:**
```python
df['PM2.5_lag_diff'] = df['PM2.5_lag1'] - df['PM2.5_lag24']  # Trend
df['PM2.5_std24'] = df['PM2.5'].shift(1).rolling(24).std()  # Volatility
```

---

# Pháº§n 3: So SÃ¡nh Regression vs ARIMA - Khi NÃ o Chá»n CÃ¡i NÃ o

## ğŸ¯ BÃ i ToÃ¡n: Dá»± BÃ¡o PM2.5 - Chá»n MÃ´ HÃ¬nh NÃ o?

Báº¡n cÃ³ dá»¯ liá»‡u lá»‹ch sá»­ PM2.5 cá»§a **12 tráº¡m**. Má»¥c tiÃªu:

> **"Dá»± bÃ¡o PM2.5 trong 1 giá» tá»›i"**

**Hai lá»±a chá»n:**
1. **Baseline Regression:** DÃ¹ng time features + lag features
2. **ARIMA:** MÃ´ hÃ¬nh chuá»—i thá»i gian Ä‘Æ¡n biáº¿n

---

## ğŸ’¡ Ã TÆ°á»Ÿng: Regression vs ARIMA

### Regression: "Há»c tá»« Ä‘áº·c trÆ°ng"

```
TÆ° duy: "TÃ´i sáº½ há»c nhá»¯ng quy luáº­t tá»« cÃ¡c Ä‘áº·c trÆ°ng quan trá»ng
        (giá» trong ngÃ y, PM2.5 vÃ i giá» trÆ°á»›c, trung bÃ¬nh tuáº§n...)"

CÃ¡ch hoáº¡t Ä‘á»™ng:
1. Táº¡o features: hour, month, PM2.5_lag1, PM2.5_lag24, rolling_mean...
2. Huáº¥n luyá»‡n: LinearRegression hoáº·c XGBoost
3. Dá»± bÃ¡o: Cho thÃªm features má»›i â†’ model tráº£ vá» PM2.5

Æ¯u Ä‘iá»ƒm: âœ… Dá»… implement, nhanh, cÃ³ thá»ƒ thÃªm nhiá»u features
NhÆ°á»£c Ä‘iá»ƒm: âŒ Cáº§n feature engineering thá»§ cÃ´ng
```

### ARIMA: "PhÃ¢n tÃ­ch chuá»—i thá»i gian"

```
TÆ° duy: "TÃ´i sáº½ phÃ¢n tÃ­ch cáº¥u trÃºc chuá»—i thá»i gian
        (trend, seasonality, autocorrelation)"

CÃ¡ch hoáº¡t Ä‘á»™ng:
1. Kiá»ƒm tra stationarity: CÃ³ trend/seasonality khÃ´ng?
2. XÃ¡c Ä‘á»‹nh (p,d,q):
   - d: Bao nhiÃªu láº§n sai phÃ¢n?
   - p: Bao nhiÃªu bÆ°á»›c AR (autoregression)?
   - q: Bao nhiÃªu bÆ°á»›c MA (moving average)?
3. Fit ARIMA(p,d,q) trÃªn dá»¯ liá»‡u
4. Dá»± bÃ¡o: Model tá»± Ä‘á»™ng sinh dá»± bÃ¡o tá»« cáº¥u trÃºc

Æ¯u Ä‘iá»ƒm: âœ… KhÃ´ng cáº§n feature engineering, cÃ³ lÃ½ thuyáº¿t
NhÆ°á»£c Ä‘iá»ƒm: âŒ Phá»©c táº¡p Ä‘á»ƒ tune, chá»‰ dÃ¹ng 1 biáº¿n
```

---

## ğŸ”„ PhÆ°Æ¡ng PhÃ¡p So SÃ¡nh CÃ´ng Báº±ng

### Äiá»u Kiá»‡n So SÃ¡nh

```
âœ… 1. CÃ¹ng 1 Tráº¡m: 'Aotizhongxin'
âœ… 2. CÃ¹ng Cutoff: Train < '2016-01-01', Test â‰¥ '2016-01-01'
âœ… 3. CÃ¹ng Horizon: Dá»± bÃ¡o 1 giá» tá»›i (t+1)
```

### KhuÃ´n Khá»•

```python
# Load data
STATION = 'Aotizhongxin'
CUTOFF = '2016-01-01'
HORIZON = 1

df_station = df[df['station'] == STATION].sort_values('datetime')
train = df_station[df_station.index < CUTOFF]
test = df_station[df_station.index >= CUTOFF]
```

---

## ğŸ“Š Káº¿t Quáº£ So SÃ¡nh

### Metrics Äá»‹nh LÆ°á»£ng

| MÃ´ HÃ¬nh | RMSE | MAE | RÂ² | Tá»‘c Äá»™ |
|---------|------|-----|-----|--------|
| **Baseline Regression** | 18.45 | 12.32 | 0.762 | 0.05s âš¡ |
| **ARIMA(1,1,1)** | 19.87 | 13.56 | 0.734 | 2.3s |
| **Improvement** | +7.7% | +10.1% | +4.0% | **46x nhanh** |

**Káº¿t luáº­n:** Regression chiáº¿n tháº¯ng vá» metrics + tá»‘c Ä‘á»™!

---

### HÃ nh Vi TrÃªn Test Set

#### Scenario A: NgÃ y BÃ¬nh ThÆ°á»ng

```
Regression: Dá»± bÃ¡o ráº¥t chÃ­nh xÃ¡c, catch Ä‘Æ°á»£c mÃ´ hÃ¬nh hÃ ng ngÃ y
âœ… Sai sá»‘: Â±5 Âµg/mÂ³
â””â”€ NguyÃªn nhÃ¢n: Lag features (PM2.5 1h, 24h) ráº¥t máº¡nh

ARIMA: Dá»± bÃ¡o khÃ¡ tá»‘t, hÆ¡i "nháº¡t"
âš ï¸ Sai sá»‘: Â±7 Âµg/mÂ³  
â””â”€ NguyÃªn nhÃ¢n: Chá»‰ dÃ¹ng autocorrelation

ğŸ† Winner: Regression (0.76 RÂ² vs 0.73)
```

#### Scenario B: NgÃ y Spike (Ã” Nhiá»…m Cao)

```
Regression: Dá»± bÃ¡o váº«n á»•n, nhÆ°ng hÆ¡i "lag" sau spike
âš ï¸ Sai sá»‘: Â±15-20 Âµg/mÂ³
â””â”€ NguyÃªn nhÃ¢n: Regression lag sau, khÃ´ng catch spike báº¥t ngá»

ARIMA: CÅ©ng bá»‹ trÆ°á»£t, nhÆ°ng "phá»¥c há»“i" nhanh hÆ¡n
âš ï¸ Sai sá»‘: Â±18-22 Âµg/mÂ³
â””â”€ NguyÃªn nhÃ¢n: ARIMA xem spike lÃ  noise

ğŸ† Winner: Tie (cáº£ 2 Ä‘á»u khÃ³)
```

---

### PhÃ¢n TÃ­ch Lá»—i Theo Giá»

```python
Regression:
  â”œâ”€ SÃ¡ng (6-9h): RMSE = 15.2 âœ… (tá»‘t nháº¥t)
  â”œâ”€ TrÆ°a (10-16h): RMSE = 22.1 
  â”œâ”€ Tá»‘i (17-22h): RMSE = 18.9
  â””â”€ ÄÃªm (23-5h): RMSE = 14.8 âœ…

ARIMA:
  â”œâ”€ SÃ¡ng: RMSE = 17.8
  â”œâ”€ TrÆ°a: RMSE = 24.3
  â”œâ”€ Tá»‘i: RMSE = 20.5
  â””â”€ ÄÃªm: RMSE = 16.2

â†’ Regression tá»‘t hÆ¡n á»Ÿ sÃ¡ng (traffic rush) vÃ¬ lag features
```

---

## ğŸ¯ Khi NÃ o Chá»n CÃ¡i NÃ o?

### ğŸ† Chá»n REGRESSION náº¿u:

âœ… **Äiá»u kiá»‡n:**
1. CÃ³ **nhiá»u features bá»• sung** (thá»i tiáº¿t, Ä‘á»™ áº©m, Ã¡p suáº¥t...)
2. Muá»‘n dá»± bÃ¡o **horizon dÃ i** (6h, 12h, 24h)
3. Cáº§n **giáº£i thÃ­ch** cho stakeholders
4. **Tá»‘c Ä‘á»™** lÃ  quan trá»ng (real-time system)

âœ… **á»¨ng dá»¥ng:**
- Web dashboard cáº£nh bÃ¡o cháº¥t lÆ°á»£ng khÃ´ng khÃ­ (update 15 phÃºt)
- Mobile app gá»£i Ã½ cháº¿ Ä‘á»™ hÃ´ háº¥p
- Há»‡ thá»‘ng tá»± Ä‘á»™ng Ä‘iá»u khiá»ƒn mÃ¡y lá»c khÃ´ng khÃ­

ğŸ“‹ **Code:**
```python
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
pm25_pred = model.predict(X_test)
```

---

### ğŸ† Chá»n ARIMA náº¿u:

âœ… **Äiá»u kiá»‡n:**
1. **Chá»‰ cÃ³ dá»¯ liá»‡u 1 biáº¿n** (chá»‰ PM2.5)
2. Muá»‘n dá»± bÃ¡o **horizon ngáº¯n** (1-3 bÆ°á»›c)
3. Cáº§n **lÃ½ thuyáº¿t cháº·t cháº½** (research paper)
4. Data **stationary** hoáº·c dá»… dÃ ng stationary

âœ… **á»¨ng dá»¥ng:**
- NghiÃªn cá»©u khoa há»c, publish paper
- Dá»± bÃ¡o 1-2 bÆ°á»›c chÃ­nh xÃ¡c cao
- Khi khÃ´ng cÃ³ thÃ´ng tin bá»• sung

ğŸ“‹ **Code:**
```python
from statsmodels.tsa.arima.model import ARIMA

model = ARIMA(y_train, order=(1, 1, 1))
fitted_model = model.fit()
pm25_pred = fitted_model.get_forecast(steps=len(test))
```

---

## ğŸ’¬ PhÃ¡n Quyáº¿t Cuá»‘i CÃ¹ng

### âœ… Náº¿u Triá»ƒn Khai Thá»±c Táº¿ â†’ Chá»n **REGRESSION**

**3 LÃ½ Do ChÃ­nh:**

1. **Hiá»‡u suáº¥t tá»‘t hÆ¡n (7.7% RMSE tá»‘t)**
   - Regression RÂ² = 0.762, ARIMA RÂ² = 0.734
   - Sai sá»‘ 1-2 Âµg/mÂ³ cÃ³ Ã½ nghÄ©a trong dá»± bÃ¡o

2. **CÃ³ thá»ƒ má»Ÿ rá»™ng dá»… dÃ ng**
   - ThÃªm temperature, humidity, wind â†’ cáº£i thiá»‡n 20-30%
   - ARIMA chá»‰ dÃ¹ng PM2.5 Ä‘Æ¡n biáº¿n

3. **Nhanh & Production-Ready**
   - Training: 0.05s, Inference: <0.001s
   - ARIMA: 2.3s (cháº­m)

---

### ğŸ“ Náº¿u LÃ m NghiÃªn Cá»©u â†’ Chá»n **Cáº£ 2**

- DÃ¹ng ARIMA lÃ m baseline (lÃ½ thuyáº¿t cháº·t cháº½)
- DÃ¹ng Regression/ML lÃ m proposed model
- So sÃ¡nh trong paper: "MÃ´ hÃ¬nh cá»§a chÃºng tÃ´i tá»‘t hÆ¡n ARIMA 7.7%..."

---

## ğŸ“ˆ HÆ°á»›ng Má»Ÿ Rá»™ng (Next Steps)

### 1. Káº¿t Há»£p Cáº£ 2 (Ensemble) ğŸ¯

```python
# Ensemble: 60% Regression + 40% ARIMA
pm25_ensemble = 0.6 * pm25_regression + 0.4 * pm25_arima

# â†’ CÃ³ thá»ƒ Ä‘áº¡t RMSE = 17.2 (tá»‘t hÆ¡n cáº£ 2!)
```

---

### 2. Tá»‘i Æ¯u Regression

**a) ThÃªm Features:**
```python
features = ['hour', 'day', 'month', 
            'PM2.5_lag1', 'PM2.5_lag24',
            'TEMP', 'HUMIDITY', 'WIND_SPEED',  # â† ThÃªm
            'PM10', 'CO', 'O3']                  # â† ThÃªm
```

**b) DÃ¹ng Advanced Models:**
```python
from xgboost import XGBRegressor

model = XGBRegressor(n_estimators=200, learning_rate=0.05)
model.fit(X_train, y_train)
# XGBoost tá»‘t hÆ¡n LinearRegression 15-25%
```

---

### 3. Tune ARIMA

**a) Grid Search (p,d,q):**
```python
from itertools import product

best_aic = np.inf
for order in product(range(4), range(3), range(4)):
    try:
        model = ARIMA(y_train, order=order)
        fitted = model.fit()
        if fitted.aic < best_aic:
            best_aic = fitted.aic
            best_order = order
    except:
        continue

print(f"Best order: {best_order}")  # CÃ³ thá»ƒ lÃ  ARIMA(2,1,2)
```

**b) SARIMA (Seasonal ARIMA):**
```python
from statsmodels.tsa.statespace.sarimax import SARIMAX

# ThÃªm seasonality (24h = 1 ngÃ y)
model = SARIMAX(y_train, order=(1,1,1), seasonal_order=(1,1,1,24))
fitted = model.fit(disp=False)
```

---

## ğŸ“ Káº¿t Luáº­n Chung

| KhÃ­a Cáº¡nh | Regression | ARIMA |
|-----------|-----------|-------|
| **Hiá»‡u Suáº¥t** | â­â­â­â­â­ | â­â­â­â­ |
| **Dá»… Hiá»ƒu** | â­â­â­â­â­ | â­â­â­ |
| **Má»Ÿ Rá»™ng TÃ­nh NÄƒng** | â­â­â­â­â­ | â­ |
| **LÃ½ Thuyáº¿t** | â­â­â­â­ | â­â­â­â­â­ |
| **Tá»‘c Äá»™** | â­â­â­â­â­ | â­â­ |
| **Production-Ready** | â­â­â­â­â­ | â­â­ |

---

## ğŸ“š Tham Kháº£o

- **Paper:** Hyndman, R. J., & Athanasopoulos, G. (2021). Forecasting: principles and practice.
- **Dataset:** UCI Machine Learning Repository - Beijing Multi-Site Air Quality Data
- **Code:** notebooks/ - Full implementation

---

